{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b02eb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed:\n",
    "# !pip install pandas numpy matplotlib openpyxl statsmodels\n",
    "\n",
    "import re, warnings, os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7386c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH  = r\"D:\\arima project\\ckd stroke\\URBANIZATION COMPLETE CKD & STROKE.xlsx\"\n",
    "SHEET_NAME = \"data final\"        # None to auto-pick; otherwise put exact sheet name\n",
    "END_YEAR   = 2043\n",
    "OUTPUT_DIR = Path(r\"D:\\arima project\\code\\ckd_stroke_results\\urbanization\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Optional: if auto-detection picks the wrong AAMR column, set this to the exact column name:\n",
    "MANUAL_AAMR_COL = None  # e.g., \"Age Adjusted Rate\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "72aaa038",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (13, 7.6),\n",
    "    \"figure.dpi\": 160,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.alpha\": 0.25,\n",
    "    \"font.size\": 14,\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"axes.labelsize\": 16,\n",
    "    \"axes.labelweight\": \"bold\",\n",
    "    \"axes.titlesize\": 20,\n",
    "    \"axes.titleweight\": \"bold\",\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"legend.frameon\": True,\n",
    "    \"legend.title_fontsize\": 13,\n",
    "    \"lines.linewidth\": 2.6,\n",
    "    \"lines.markersize\": 6.5,\n",
    "})\n",
    "def style_axes(ax):\n",
    "    ax.tick_params(axis=\"both\", labelsize=14, width=1.9, length=6)\n",
    "    for s in ax.spines.values():\n",
    "        s.set_linewidth(2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "03ed6c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet: data final\n",
      "Detected → Year: 'Year' | AAMR: 'Age Adjusted Rate' | Group: 'Census Region'\n",
      "First rows:\n",
      "    Year                       Group   AAMR\n",
      "0  1999  Census Region 1: Northeast  16.38\n",
      "1  2000  Census Region 1: Northeast  15.69\n",
      "2  2001  Census Region 1: Northeast  15.68\n",
      "3  2002  Census Region 1: Northeast  16.20\n",
      "4  2003  Census Region 1: Northeast  15.07\n",
      "5  2004  Census Region 1: Northeast  14.33\n"
     ]
    }
   ],
   "source": [
    "def _flatten_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Flatten multirow headers, normalize whitespace, and deduplicate names.\"\"\"\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [\n",
    "            \" \".join([str(x) for x in tup if (str(x) != \"nan\" and str(x).strip() != \"\")]).strip()\n",
    "            for tup in df.columns.to_list()\n",
    "        ]\n",
    "    df.columns = [re.sub(r\"\\s+\", \" \", str(c)).strip() for c in df.columns]\n",
    "    seen, newcols = {}, []\n",
    "    for c in df.columns:\n",
    "        if c in seen:\n",
    "            seen[c] += 1; newcols.append(f\"{c}.{seen[c]}\")\n",
    "        else:\n",
    "            seen[c] = 0;  newcols.append(c)\n",
    "    df.columns = newcols\n",
    "    return df\n",
    "\n",
    "def _pick_col(df, patterns, required=True, exclude_regex=None):\n",
    "    low = {c: str(c).strip().lower() for c in df.columns}\n",
    "    for pat in patterns:\n",
    "        rx = re.compile(pat)\n",
    "        for c, lc in low.items():\n",
    "            if rx.search(lc):\n",
    "                if exclude_regex and re.search(exclude_regex, lc):\n",
    "                    continue\n",
    "                return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Could not find any of: {patterns}\")\n",
    "    return None\n",
    "\n",
    "def find_year(df):  # prefer 'Year'\n",
    "    return _pick_col(df, [r\"\\byear\\b\", r\"^yr$\", r\"\\bcalendar\\s*year\\b\"])\n",
    "\n",
    "def find_aamr(df):\n",
    "    if MANUAL_AAMR_COL and MANUAL_AAMR_COL in df.columns:\n",
    "        return MANUAL_AAMR_COL\n",
    "    # Be precise so we don't confuse with \"Age group\"\n",
    "    pats = [\n",
    "        r\"\\bage[-\\s]*adjust(ed)?\\s*rate\\b\",\n",
    "        r\"\\baamr\\b\",\n",
    "        r\"\\bage[-\\s]*standard(ized)?\\s*rate\\b\"\n",
    "    ]\n",
    "    # also allow generic \"age adjust\" + \"rate\" together\n",
    "    low = {c: str(c).strip().lower() for c in df.columns}\n",
    "    # exact patterns first\n",
    "    for p in pats:\n",
    "        try: return _pick_col(df, [p])\n",
    "        except: pass\n",
    "    # fallback: both 'age'+'adjust' and 'rate' in name\n",
    "    for c, lc in low.items():\n",
    "        if all(k in lc for k in [\"age\",\"adjust\"]) and \"rate\" in lc:\n",
    "            return c\n",
    "    # last resort: a column literally named 'AAMR' somewhere\n",
    "    return _pick_col(df, [r\"\\baamr\\b\"])\n",
    "\n",
    "def find_group(df):\n",
    "    \"\"\"True grouping column (Age group / variable / Sex / Race / Region / Urbanization / State).\"\"\"\n",
    "    exclude = r\"age\\s*adjust|aamr|rate|ci|confidence|se|std|mean|median|total|overall\"\n",
    "    patterns = [\n",
    "        r\"\\bvariable\\b\",\n",
    "        r\"\\bage\\s*group(s)?\\b|age\\s*cat(egory|egories)?\\b|age\\s*grp\\b|age\\-group\",\n",
    "        r\"\\bgender\\b|\\bsex\\b\",\n",
    "        r\"\\brace\\b|ethnic|hispanic\",\n",
    "        r\"\\bregion\\b|census\",\n",
    "        r\"\\burban(ization)?\\b|rural\\b\",\n",
    "        r\"\\bstate\\b|^us state$|^state name$\",\n",
    "        r\"\\boverall\\b|^total$\"\n",
    "    ]\n",
    "    for pat in patterns:\n",
    "        try:\n",
    "            c = _pick_col(df, [pat], required=False, exclude_regex=exclude)\n",
    "            if c: return c\n",
    "        except: \n",
    "            pass\n",
    "    return None  # overall-only\n",
    "\n",
    "def load_observed_excel(path, sheet_name=None, overall_label=\"Overall\"):\n",
    "    xls = pd.ExcelFile(path)\n",
    "    chosen = sheet_name or next(\n",
    "        (s for s in xls.sheet_names if \"data\" in s.lower() and \"final\" in s.lower()),\n",
    "        xls.sheet_names[0]\n",
    "    )\n",
    "    df = pd.read_excel(xls, sheet_name=chosen)\n",
    "    df = _flatten_columns(df)\n",
    "\n",
    "    ycol = find_year(df)\n",
    "    tcol = find_aamr(df)\n",
    "    gcol = find_group(df)  # may be None\n",
    "\n",
    "    df[ycol] = pd.to_numeric(df[ycol], errors=\"coerce\")\n",
    "    df[tcol] = pd.to_numeric(df[tcol], errors=\"coerce\")\n",
    "\n",
    "    if gcol == tcol:  # safety\n",
    "        gcol = None\n",
    "\n",
    "    if gcol is None:\n",
    "        tidy = (df[[ycol, tcol]]\n",
    "                .dropna(subset=[ycol, tcol])\n",
    "                .groupby(ycol, as_index=False)[tcol].mean()\n",
    "                .rename(columns={ycol:\"Year\", tcol:\"AAMR\"}))\n",
    "        tidy[\"Group\"] = overall_label\n",
    "        tidy = tidy[[\"Year\",\"Group\",\"AAMR\"]]\n",
    "    else:\n",
    "        df[gcol] = df[gcol].astype(str).str.strip()\n",
    "        tidy = (df[[ycol, gcol, tcol]]\n",
    "                .dropna(subset=[ycol, gcol, tcol])\n",
    "                .groupby([ycol, gcol], as_index=False)[tcol].mean()\n",
    "                .rename(columns={ycol:\"Year\", gcol:\"Group\", tcol:\"AAMR\"}))\n",
    "\n",
    "    tidy[\"Year\"] = tidy[\"Year\"].astype(int)\n",
    "    tidy = tidy.sort_values([\"Group\",\"Year\"]).reset_index(drop=True)\n",
    "\n",
    "    print(f\"Sheet: {chosen}\")\n",
    "    print(f\"Detected → Year: '{ycol}' | AAMR: '{tcol}' | Group: '{(gcol or overall_label)}'\")\n",
    "    print(\"First rows:\\n\", tidy.head(6))\n",
    "    return tidy\n",
    "\n",
    "observed = load_observed_excel(FILE_PATH, sheet_name=SHEET_NAME, overall_label=\"Overall\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f5cd67bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sanitize_series_for_arima(y: pd.Series):\n",
    "    y = y.sort_index()\n",
    "    full = pd.Index(range(int(y.index.min()), int(y.index.max())+1), name=y.index.name)\n",
    "    y = y.reindex(full)\n",
    "    if y.isna().any():\n",
    "        y = y.interpolate(limit_direction=\"both\")\n",
    "    return y\n",
    "\n",
    "def select_arima_order(y):\n",
    "    best = None\n",
    "    for d in [0,1,2]:\n",
    "        for p in range(0,4):\n",
    "            for q in range(0,4):\n",
    "                if (p,d,q) == (0,0,0): \n",
    "                    continue\n",
    "                try:\n",
    "                    trend = \"n\" if d>0 else \"c\"\n",
    "                    res = ARIMA(y, order=(p,d,q), trend=trend,\n",
    "                                enforce_stationarity=False, enforce_invertibility=False\n",
    "                               ).fit(method_kwargs={\"warn_convergence\":False})\n",
    "                    score = res.aic\n",
    "                    if (best is None) or (score < best[0]):\n",
    "                        best = (score, (p,d,q,trend), res)\n",
    "                except Exception:\n",
    "                    pass\n",
    "    if best is None:\n",
    "        res = ARIMA(y, order=(1,1,0), trend=\"n\",\n",
    "                    enforce_stationarity=False, enforce_invertibility=False\n",
    "                   ).fit(method_kwargs={\"warn_convergence\":False})\n",
    "        return (1,1,0,\"n\"), res\n",
    "    return best[1], best[2]\n",
    "\n",
    "def forecast_to(y, end_year, conf=0.95):\n",
    "    last_year = int(y.index.max())\n",
    "    steps = max(0, end_year - last_year)\n",
    "    if steps == 0:\n",
    "        raise ValueError(\"Observed series already extends to END_YEAR.\")\n",
    "    order, res = select_arima_order(y)\n",
    "    fc = res.get_forecast(steps=steps)\n",
    "    mean = fc.predicted_mean\n",
    "    ci   = fc.conf_int(alpha=1-conf)\n",
    "    lo, hi = ci.iloc[:,0], ci.iloc[:,1]\n",
    "    yrs = list(range(last_year+1, end_year+1))\n",
    "    out = pd.DataFrame({\n",
    "        \"Year\": yrs,\n",
    "        \"Point.Forecast\": mean.values,\n",
    "        \"Lo.95\": lo.values,\n",
    "        \"Hi.95\": hi.values,\n",
    "        \"Order\": [f\"{order[0]},{order[1]},{order[2]} ({order[3]})\"]*steps\n",
    "    })\n",
    "    return order, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "75874ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Census Region 1: Northeast] order=(0, 2, 3, 'n')  -> saved CSV: D:\\arima project\\code\\ckd_stroke_results\\region\\Census_Region_1_Northeast_forecast_to_2043.csv\n",
      "   saved plot: D:\\arima project\\code\\ckd_stroke_results\\region\\Census_Region_1_Northeast_timeseries_to_2043.png\n",
      "[Census Region 2: Midwest] order=(0, 2, 3, 'n')  -> saved CSV: D:\\arima project\\code\\ckd_stroke_results\\region\\Census_Region_2_Midwest_forecast_to_2043.csv\n",
      "   saved plot: D:\\arima project\\code\\ckd_stroke_results\\region\\Census_Region_2_Midwest_timeseries_to_2043.png\n",
      "[Census Region 3: South] order=(0, 2, 3, 'n')  -> saved CSV: D:\\arima project\\code\\ckd_stroke_results\\region\\Census_Region_3_South_forecast_to_2043.csv\n",
      "   saved plot: D:\\arima project\\code\\ckd_stroke_results\\region\\Census_Region_3_South_timeseries_to_2043.png\n",
      "[Census Region 4: West] order=(0, 2, 3, 'n')  -> saved CSV: D:\\arima project\\code\\ckd_stroke_results\\region\\Census_Region_4_West_forecast_to_2043.csv\n",
      "   saved plot: D:\\arima project\\code\\ckd_stroke_results\\region\\Census_Region_4_West_timeseries_to_2043.png\n",
      "Saved consolidated CSV: D:\\arima project\\code\\ckd_stroke_results\\region\\ALL_GROUPS_forecasts_to_2043.csv\n"
     ]
    }
   ],
   "source": [
    "def safe_name(s: str) -> str:\n",
    "    return re.sub(r\"[^a-zA-Z0-9_-]+\", \"_\", str(s)).strip(\"_\")\n",
    "\n",
    "def fit_all_groups_and_save(observed_df, end_year, out_dir: Path, title_prefix=\"CKD & Stroke\"):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    groups = sorted(observed_df[\"Group\"].unique())\n",
    "    all_rows = []\n",
    "    last_obs_year = int(observed_df[\"Year\"].max())\n",
    "\n",
    "    for g in groups:\n",
    "        sub = observed_df[observed_df[\"Group\"]==g].copy()\n",
    "        sub = sub.dropna(subset=[\"Year\",\"AAMR\"]).sort_values(\"Year\")\n",
    "        y = pd.Series(sub[\"AAMR\"].values, index=sub[\"Year\"].astype(int), name=\"AAMR\")\n",
    "        y = _sanitize_series_for_arima(y)\n",
    "\n",
    "        order, fc = forecast_to(y, end_year=end_year, conf=0.95)\n",
    "\n",
    "        # save per-group csv (two decimals)\n",
    "        csv_path = out_dir / f\"{safe_name(g)}_forecast_to_{end_year}.csv\"\n",
    "        fc_out = fc.copy()\n",
    "        for c in [\"Point.Forecast\",\"Lo.95\",\"Hi.95\"]:\n",
    "            fc_out[c] = fc_out[c].round(2)\n",
    "        fc_out.insert(0, \"Series\", g)\n",
    "        fc_out.to_csv(csv_path, index=False)\n",
    "        print(f\"[{g}] order={order}  -> saved CSV:\", csv_path)\n",
    "\n",
    "        # keep for consolidated\n",
    "        tmp = fc_out.copy(); tmp[\"Group\"] = g\n",
    "        all_rows.append(tmp)\n",
    "\n",
    "        # per-group plot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(y.index, y.values, marker=\"o\", label=f\"{g} (obs)\")\n",
    "        ln, = ax.plot(fc[\"Year\"], fc[\"Point.Forecast\"], linestyle=\"--\", marker=\"o\", label=f\"{g} (fc)\")\n",
    "        ax.fill_between(fc[\"Year\"], fc[\"Lo.95\"], fc[\"Hi.95\"], alpha=0.14, color=ln.get_color(), label=\"95% CI (fc)\")\n",
    "        ax.axvline(x=last_obs_year+0.5, linestyle=\":\", linewidth=2.0)\n",
    "        ax.set_title(f\"{title_prefix}: {g} — observed (≤{last_obs_year}) & ARIMA forecast ({last_obs_year+1}–{end_year})\")\n",
    "        ax.set_xlabel(\"Year\"); ax.set_ylabel(\"AAMR (per 100,000)\")\n",
    "        ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.2f\"))\n",
    "        style_axes(ax)\n",
    "        ax.legend(ncols=2)\n",
    "        plt.tight_layout()\n",
    "        png_path = out_dir / f\"{safe_name(g)}_timeseries_to_{end_year}.png\"\n",
    "        plt.savefig(png_path, dpi=300, bbox_inches=\"tight\"); plt.close()\n",
    "        print(\"   saved plot:\", png_path)\n",
    "\n",
    "    if all_rows:\n",
    "        all_df = pd.concat(all_rows, ignore_index=True)\n",
    "        all_df.to_csv(out_dir / f\"ALL_GROUPS_forecasts_to_{end_year}.csv\", index=False)\n",
    "        print(\"Saved consolidated CSV:\", out_dir / f\"ALL_GROUPS_forecasts_to_{end_year}.csv\")\n",
    "\n",
    "fit_all_groups_and_save(observed, END_YEAR, OUTPUT_DIR, title_prefix=\"CKD & Stroke\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "34e0a78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined plot: D:\\arima project\\code\\ckd_stroke_results\\region\\COMBINED_timeseries_to_2043.png\n"
     ]
    }
   ],
   "source": [
    "def plot_combined(observed_df, out_dir:Path, end_year:int, title=\"CKD & Stroke\"):\n",
    "    last_obs_year = int(observed_df[\"Year\"].max())\n",
    "    groups = sorted(observed_df[\"Group\"].unique())\n",
    "\n",
    "    # read saved forecasts for CI\n",
    "    fc_map = {}\n",
    "    for g in groups:\n",
    "        p = out_dir / f\"{safe_name(g)}_forecast_to_{end_year}.csv\"\n",
    "        if p.exists():\n",
    "            fc_map[g] = pd.read_csv(p)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ci_legend_added = False\n",
    "\n",
    "    for g in groups:\n",
    "        sub = observed_df[observed_df[\"Group\"]==g].copy().sort_values(\"Year\")\n",
    "        ax.plot(sub[\"Year\"], sub[\"AAMR\"], marker=\"o\", label=f\"{g} (obs)\")\n",
    "        if g in fc_map:\n",
    "            fc = fc_map[g]\n",
    "            ln, = ax.plot(fc[\"Year\"], fc[\"Point.Forecast\"], linestyle=\"--\", marker=\"o\", label=f\"{g} (fc)\")\n",
    "            # one legend entry for CI:\n",
    "            if not ci_legend_added:\n",
    "                ax.fill_between(fc[\"Year\"], fc[\"Lo.95\"], fc[\"Hi.95\"], alpha=0.12, color=ln.get_color(), label=\"95% CI (fc)\")\n",
    "                ci_legend_added = True\n",
    "            else:\n",
    "                ax.fill_between(fc[\"Year\"], fc[\"Lo.95\"], fc[\"Hi.95\"], alpha=0.12, color=ln.get_color())\n",
    "\n",
    "    ax.axvline(x=last_obs_year+0.5, linestyle=\":\", linewidth=2.0)\n",
    "    ax.set_title(f\"{title}: observed (≤{last_obs_year}) & ARIMA forecast ({last_obs_year+1}–{end_year})\")\n",
    "    ax.set_xlabel(\"Year\"); ax.set_ylabel(\"AAMR (per 100,000)\")\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.2f\"))\n",
    "    style_axes(ax)\n",
    "    ax.legend(ncols=2)\n",
    "    ax.margins(x=0.02)\n",
    "    plt.tight_layout()\n",
    "    out = out_dir / f\"COMBINED_timeseries_to_{end_year}.png\"\n",
    "    plt.savefig(out, dpi=300, bbox_inches=\"tight\"); plt.close()\n",
    "    print(\"Saved combined plot:\", out)\n",
    "    \n",
    "plot_combined(observed, OUTPUT_DIR, END_YEAR, title=\"CKD & Stroke\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41587877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d636fc51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f0f56c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
